{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Veriyi okuyun\n",
    "X = pd.read_csv('data/train.csv', index_col='Id') \n",
    "X_test = pd.read_csv('data/test.csv', index_col='Id')\n",
    "\n",
    "# Hedef değişkeni eksik olan satırları çıkarın ve hedefi değişkeni ayırın\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Eksik değeri olan sütunları çıkarın\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()] \n",
    "X.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_test.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# Eğitim ve doğrulama veri setlerini ayırın\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,train_size=0.8, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verilerin ilk beş satırını yazdırmak için bir sonraki kod hücresini kullanın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>11694</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>6600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>13360</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>13265</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>13704</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass MSZoning  LotArea Street LotShape LandContour Utilities  \\\n",
       "Id                                                                        \n",
       "619          20       RL    11694   Pave      Reg         Lvl    AllPub   \n",
       "871          20       RL     6600   Pave      Reg         Lvl    AllPub   \n",
       "93           30       RL    13360   Pave      IR1         HLS    AllPub   \n",
       "818          20       RL    13265   Pave      IR1         Lvl    AllPub   \n",
       "303          20       RL    13704   Pave      IR1         Lvl    AllPub   \n",
       "\n",
       "    LotConfig LandSlope Neighborhood  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "Id                                    ...                                       \n",
       "619    Inside       Gtl      NridgHt  ...         108             0         0   \n",
       "871    Inside       Gtl        NAmes  ...           0             0         0   \n",
       "93     Inside       Gtl      Crawfor  ...           0            44         0   \n",
       "818   CulDSac       Gtl      Mitchel  ...          59             0         0   \n",
       "303    Corner       Gtl      CollgCr  ...          81             0         0   \n",
       "\n",
       "    ScreenPorch  PoolArea  MiscVal  MoSold  YrSold SaleType SaleCondition  \n",
       "Id                                                                         \n",
       "619         260         0        0       7    2007      New       Partial  \n",
       "871           0         0        0       8    2009       WD        Normal  \n",
       "93            0         0        0       8    2009       WD        Normal  \n",
       "818           0         0        0       7    2008       WD        Normal  \n",
       "303           0         0        0       1    2006       WD        Normal  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri setinin hem sayısal hem de kategorik değişkenler içerdiğine dikkat edin. Bir modeli eğitmeden önce kategorik verileri kodlamanız gerekecektir.\n",
    "\n",
    "Farklı modelleri karşılaştırmak için, eğitimdeki aynı `score_dataset()` işlevini kullanacaksınız. Bu işlev, rastgele bir orman modelinden [ortalama mutlak hatayı](https://en.wikipedia.org/wiki/Mean_absolute_error) (MAE) bildirir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Farklı yaklaşımları karşılaştırmak için fonksiyon \n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    # Random Forest modelini oluşturun ve eğitin\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Doğrulama seti üzerinde tahmin yapın\n",
    "    preds = model.predict(X_valid)\n",
    "    \n",
    "    # Ortalama mutlak hata (MAE) hesaplayın ve döndürün\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soru1 : Kategorik veriler içeren sütunları kaldırın\n",
    "\n",
    "En basit yaklaşımla başlayacaksınız. Kategorik veriler içeren sütunları kaldırmak için `X_train` ve `X_valid` içindeki verileri önceden işlemek için aşağıdaki kod hücresini kullanın. Önceden işlenmiş DataFrames'i sırasıyla `drop_X_train` ve `drop_X_valid` olarak ayarlayın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kategorik veri tipine sahip sütunları çıkar: eğitim ve doğrulama verisi için\n",
    "# Eğitim verisinden 'object' tipindeki sütunları çıkar\n",
    "drop_X_train = X_train.select_dtypes(exclude=[\"object\"]) \n",
    "# Doğrulama verisinden 'object' tipindeki sütunları çıkar\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=[\"object\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu yaklaşım için MAE'yi almak üzere bir sonraki kod hücresini çalıştırın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop categorical variables):\n",
      "17837.82570776256\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sıralı kodlamaya geçmeden önce, veri kümesini inceleyeceğiz. Özellikle `'Condition2'` sütununa bakacağız. Aşağıdaki kod hücresi, hem eğitim hem de doğrulama kümelerindeki benzersiz girdileri yazdırır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Condition2' column in training data: ['Norm' 'PosA' 'Feedr' 'PosN' 'Artery' 'RRAe']\n",
      "\n",
      "Unique values in 'Condition2' column in validation data: ['Norm' 'RRAn' 'RRNn' 'Artery' 'Feedr' 'PosN']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\n",
    "print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soru2: Sıralı kodlama\n",
    "\n",
    "### Bölüm A\n",
    "\n",
    "Şimdi şu kodu yazarsanız:\n",
    "- eğitim verilerine ordinal bir kodlayıcı uydurun ve sonra\n",
    "- hem eğitim hem de doğrulama verilerini dönüştürmek için kullanın,\n",
    "\n",
    "bir hata alırsınız. Bunun neden böyle olduğunu görebiliyor musunuz? (_Bu soruyu cevaplamak için yukarıdaki çıktıyı kullanmanız gerekir._)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu, gerçek dünya verileriyle karşılaşacağınız yaygın bir sorundur ve bu sorunu çözmek için birçok yaklaşım vardır. Örneğin, yeni kategorilerle başa çıkmak için özel bir sıra kodlayıcı yazabilirsiniz. Ancak en basit yaklaşım, sorunlu kategorik sütunları bırakmaktır.\n",
    "\n",
    "Sorunlu sütunları bir Python listesi `bad_label_cols`'a kaydetmek için aşağıdaki kod hücresini çalıştırın. Benzer şekilde, güvenli bir şekilde sıra kodlanabilen sütunlar `good_label_cols`'da saklanır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sıralı kodlanacak kategorik sütunlar: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'BldgType', 'HouseStyle', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Veri setinden çıkarılacak kategorik sütunlar: ['Functional', 'Condition2', 'RoofMatl']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ngood_label_cols:\\nDoğrulama setindeki değerler, eğitim setindekilerin bir alt kümesi olan sütunları bulur.\\n\\nbad_label_cols:\\nDoğrulama setinde eğitim setinde olmayan değerler içeren sütunları bulur ve bunları çıkarır.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eğitim verisindeki kategorik sütunlar\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# Sıralı kodlama için uygun sütunlar\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_valid[col]).issubset(set(X_train[col]))]\n",
    "        \n",
    "# Sıralı kodlama için uygun olmayan, veri setinden çıkarılacak sütunlar\n",
    "bad_label_cols = list(set(object_cols) - set(good_label_cols))\n",
    "        \n",
    "print('Sıralı kodlanacak kategorik sütunlar:', good_label_cols)\n",
    "print('\\nVeri setinden çıkarılacak kategorik sütunlar:', bad_label_cols)\n",
    "\n",
    "'''\n",
    "good_label_cols:\n",
    "Doğrulama setindeki değerler, eğitim setindekilerin bir alt kümesi olan sütunları bulur.\n",
    "\n",
    "bad_label_cols:\n",
    "Doğrulama setinde eğitim setinde olmayan değerler içeren sütunları bulur ve bunları çıkarır.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bölüm B\n",
    "\n",
    "`X_train` ve `X_valid` içindeki verileri sıralı olarak kodlamak için bir sonraki kod hücresini kullanın. Önceden işlenmiş Veri Çerçevelerini sırasıyla `label_X_train` ve `label_X_valid` olarak ayarlayın.\n",
    "- `bad_label_cols` içindeki kategorik sütunları veri kümesinden çıkarmak için aşağıda kod sağladık.\n",
    "- `good_label_cols` içindeki kategorik sütunları sıralı olarak kodlamalısınız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Kodlanmayacak kategorik sütunları çıkar\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# Sıralı kodlayıcıyı uygula\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Eğitim ve doğrulama verilerindeki uygun sütunları sıralı kodlama yöntemiyle dönüştür\n",
    "label_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n",
    "label_X_valid[good_label_cols] = ordinal_encoder.transform(X_valid[good_label_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu yaklaşım için MAE'yi almak üzere bir sonraki kod hücresini çalıştırın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Ordinal Encoding):\n",
      "17098.01649543379\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 2 (Ordinal Encoding):\") \n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdiye kadar kategorik değişkenlerle başa çıkmak için iki farklı yaklaşım denediniz. Ve kategorik verileri kodlamanın, veri kümesinden sütunları kaldırmaktan daha iyi sonuçlar verdiğini gördünüz.\n",
    "\n",
    "Yakında, one hot encoding kodlamayı deneyeceksiniz. Ondan önce, ele almamız gereken ek bir konu var. Bir sonraki kod hücresini değişiklik yapmadan çalıştırarak başlayın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Street', 2),\n",
       " ('Utilities', 2),\n",
       " ('CentralAir', 2),\n",
       " ('LandSlope', 3),\n",
       " ('PavedDrive', 3),\n",
       " ('LotShape', 4),\n",
       " ('LandContour', 4),\n",
       " ('ExterQual', 4),\n",
       " ('KitchenQual', 4),\n",
       " ('MSZoning', 5),\n",
       " ('LotConfig', 5),\n",
       " ('BldgType', 5),\n",
       " ('ExterCond', 5),\n",
       " ('HeatingQC', 5),\n",
       " ('Condition2', 6),\n",
       " ('RoofStyle', 6),\n",
       " ('Foundation', 6),\n",
       " ('Heating', 6),\n",
       " ('Functional', 6),\n",
       " ('SaleCondition', 6),\n",
       " ('RoofMatl', 7),\n",
       " ('HouseStyle', 8),\n",
       " ('Condition1', 9),\n",
       " ('SaleType', 9),\n",
       " ('Exterior1st', 15),\n",
       " ('Exterior2nd', 16),\n",
       " ('Neighborhood', 25)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kategorik verilere sahip her sütundaki benzersiz girişlerin sayısını alın\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "\n",
    "# Sütun adları ve benzersiz giriş sayıları ile bir sözlük oluşturun\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# Benzersiz giriş sayısına göre sütunları artan sırayla yazdırın\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soru 3: Kardinaliteyi araştırma\n",
    "\n",
    "### Bölüm A\n",
    "\n",
    "Yukarıdaki çıktı, kategorik verilerin bulunduğu her sütun için sütundaki benzersiz değerlerin sayısını gösterir. Örneğin, eğitim verilerindeki `'Sokak'' sütununun iki benzersiz değeri vardır: `'Grvl'' ve `'Pave'', sırasıyla çakıl yol ve asfalt yola karşılık gelir.\n",
    "\n",
    "Bir kategorik değişkenin benzersiz giriş sayısına, o kategorik değişkenin **kardinalitesi** olarak atıfta bulunuruz. Örneğin, `'Sokak'' değişkeninin kardinalitesi 2'dir.\n",
    "\n",
    "Aşağıdaki soruları yanıtlamak için yukarıdaki çıktıyı kullanın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim verisinde kardinalitesi 10'dan büyük olan kaç tane kategorik değişken var?\n",
    "high_cardinality_numcols = 3  # (Kardinalitesi 10'dan büyük sütun sayısı)\n",
    "\n",
    "# Eğitim verisindeki 'Neighborhood' değişkenini one-hot kodlamak için kaç sütun gerekli?\n",
    "num_cols_neighborhood = 25  # ('Neighborhood' değişkeni için gereken one-hot sütun sayısı)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bölüm B\n",
    "\n",
    "Çok sayıda satıra sahip büyük veri kümeleri için, tek sıcak kodlama veri kümesinin boyutunu büyük ölçüde genişletebilir. Bu nedenle, genellikle yalnızca nispeten düşük kardinaliteye sahip sütunları tek sıcak kodlayacağız. Daha sonra, yüksek kardinaliteye sahip sütunlar veri kümesinden çıkarılabilir veya sıralı kodlama kullanabiliriz.\n",
    "\n",
    "Örnek olarak, 10.000 satıra sahip ve 100 benzersiz girişi olan bir kategorik sütun içeren bir veri kümesini ele alalım.\n",
    "\n",
    "- Bu sütun karşılık gelen tek sıcak kodlamayla değiştirilirse, veri kümesine kaç giriş eklenir?\n",
    "\n",
    "- Bunun yerine sütunu sıralı kodlamayla değiştirirsek, kaç giriş eklenir?\n",
    "\n",
    "Cevaplarınızı aşağıdaki satırları doldurmak için kullanın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sütunu one-hot kodlama ile değiştirdiğimizde veri setine kaç giriş eklenir?\n",
    "OH_entries_added = 1e4 * 100 - 1e4  # (Yeni sütun sayısı * satır sayısı - orijinal sütun sayısı)\n",
    "\n",
    "# Sütunu sıralı (ordinal) kodlama ile değiştirdiğimizde veri setine kaç giriş eklenir?\n",
    "label_entries_added = 0  # (Sıralı kodlama ek sütun eklemez, sadece mevcut sütunu dönüştürür)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sonra, tone-hot-wncoding kodlamayı deneyeceksiniz. Ancak, veri kümesindeki tüm kategorik değişkenleri kodlamak yerine, yalnızca kardinalitesi 10'dan küçük olan sütunlar için tek-sıcak kodlama oluşturacaksınız.\n",
    "\n",
    "Aşağıdaki kod hücresini, `low_cardinality_cols`'u tek-sıcak kodlanacak sütunları içeren bir Python listesine ayarlamak için değişiklik yapmadan çalıştırın. Benzer şekilde, `high_cardinality_cols` veri kümesinden kaldırılacak kategorik sütunların bir listesini içerir.;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot kodlanacak kategorik sütunlar: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Veri setinden çıkarı\n"
     ]
    }
   ],
   "source": [
    "# One-hot kodlanacak sütunlar: Kardinalitesi 10'dan az olan kategorik sütunlar\n",
    "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
    "\n",
    "# Veri setinden çıkarılacak sütunlar: Kardinalitesi yüksek olan kategorik sütunlar\n",
    "high_cardinality_cols = list(set(object_cols) - set(low_cardinality_cols))\n",
    "\n",
    "# One-hot kodlanacak kategorik sütunları yazdır\n",
    "print('One-hot kodlanacak kategorik sütunlar:', low_cardinality_cols)\n",
    "# Veri setinden çıkarılacak kategorik sütunları yazdır\n",
    "print('\\nVeri setinden çıkarı')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soru 4: One-Hot kodlama\n",
    "\n",
    "`X_train` ve `X_valid` içindeki verileri tek sıcak kodlamak için bir sonraki kod hücresini kullanın. Önceden işlenmiş DataFrames'i sırasıyla `OH_X_train` ve `OH_X_valid` olarak ayarlayın.\n",
    "- Veri setindeki kategorik sütunların tam listesi Python listesi `object_cols` içinde bulunabilir.\n",
    "- `low_cardinalite_cols` içindeki kategorik sütunları yalnızca tek sıcak kodlamanız gerekir. Diğer tüm kategorik sütunlar veri setinden çıkarılmalıdır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One-hot kodlayıcıyı her kategorik veri sütununa uygulayın\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "\n",
    "# One-hot kodlama sırasında kaybolan indeksleri geri yükleyin\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Kategorik sütunları çıkarın (bunlar one-hot kodlama ile değiştirilecek)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# One-hot kodlanmış sütunları sayısal özelliklerle birleştirin\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "OH_X_train.columns = OH_X_train.columns.astype(str)\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu yaklaşım için MAE'yi almak üzere bir sonraki kod hücresini çalıştırın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (One-Hot Encoding):\n",
      "17525.345719178084\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Your code here"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 111096,
     "sourceId": 10211,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
